{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/irs38/.conda/envs/contrastive/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading: 100%|██████████| 694/694 [00:00<00:00, 2.87MB/s]\n",
      "Downloading: 100%|██████████| 597M/597M [00:06<00:00, 96.9MB/s] \n",
      "Downloading: 100%|██████████| 899k/899k [00:00<00:00, 12.1MB/s]\n",
      "Downloading: 100%|██████████| 456k/456k [00:00<00:00, 5.65MB/s]\n",
      "Downloading: 100%|██████████| 1.36M/1.36M [00:00<00:00, 17.1MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params({'dataset_reader': {'token_indexers': {'tokens': {'max_length': 4096, 'model_name': 'allenai/longformer-base-4096', 'type': 'pretrained_transformer'}}, 'tokenizer': {'add_special_tokens': False, 'model_name': 'allenai/longformer-base-4096', 'type': 'pretrained_transformer'}, 'type': 'ecthr'}, 'trainer': {'cuda_device': 0, 'learning_rate_scheduler': {'cut_frac': 0.06, 'type': 'slanted_triangular'}, 'num_epochs': 2, 'optimizer': {'lr': 2e-06, 'type': 'huggingface_adamw', 'weight_decay': 0.1}, 'patience': 5, 'use_amp': True, 'validation_metric': '+accuracy'}, 'evaluate_on_test': True, 'train_data_path': 'data/ecthr/Chalkidis/simple_train.jsonl', 'validation_data_path': 'data/ecthr/Chalkidis/simple_val.jsonl', 'test_data_path': 'data/ecthr/Chalkidis/simple_test.jsonl', 'data_loader': {'batch_sampler': {'batch_size': 1, 'type': 'bucket'}}, 'model': {'dropout': 0.1, 'feedforward': {'activations': 'tanh', 'hidden_dims': 768, 'input_dim': 768, 'num_layers': 1}, 'namespace': 'tags', 'seq2vec_encoder': {'embedding_dim': 768, 'type': 'cls_pooler'}, 'text_field_embedder': {'token_embedders': {'tokens': {'max_length': 4096, 'model_name': 'allenai/longformer-base-4096', 'type': 'pretrained_transformer'}}}, 'type': 'ecthr'}})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'not_claimed': 0, 'claimed_and_violated': 1, 'claimed_not_violated': 2}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "from allennlp.common.util import import_module_and_submodules as import_submodules\n",
    "from allennlp.models.archival import load_archive\n",
    "from allennlp.predictors import Predictor\n",
    "from scipy.spatial import distance\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "import_submodules(\"allennlp_lib\")\n",
    "\n",
    "DATASET=\"ecthr\"\n",
    "MODEL_NAME=\"allenai/longformer-base-4096\"\n",
    "model_path=f\"../experiments/models/{DATASET}/{MODEL_NAME}\"\n",
    "\n",
    "archive = load_archive(model_path + '/model.tar.gz')\n",
    "print(archive.config)\n",
    "archive.config['dataset_reader']['type'] = 'ecthr'\n",
    "archive.config['model']['output_hidden_states'] = True\n",
    "model = archive.model\n",
    "model._output_hidden_states = True\n",
    "predictor = Predictor.from_archive(archive, 'ecthr')\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained(\"allenai/longformer-base-4096\")\n",
    "\n",
    "with open(model_path + \"/label2index.json\", \"r\") as f:\n",
    "    label2index = json.load(f)\n",
    "    index2label = {label2index[k]: k for k in label2index}\n",
    "label2index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def all_masks(tokenized_text):\n",
    "    # https://stackoverflow.com/questions/1482308/how-to-get-all-subsets-of-a-set-powerset\n",
    "    # WITHOUT empty and full sets!\n",
    "    s = list(range(len(tokenized_text)))\n",
    "    x = len(s)\n",
    "    masks = [1 << i for i in range(x)]\n",
    "    #     for i in range(1 << x):  # empty and full sets included here\n",
    "    for i in range(1, 1 << x - 1):\n",
    "        yield [ss for mask, ss in zip(masks, s) if i & mask]\n",
    "        \n",
    "def all_consecutive_masks(tokenized_text, max_length = -1):\n",
    "    # WITHOUT empty and full sets!\n",
    "    s = list(range(len(tokenized_text)))\n",
    "    x = len(s)\n",
    "    for i in range(x):\n",
    "        for j in range(i+1, x):\n",
    "            mask = s[:i] + s[j:]\n",
    "            if max_length > 0:\n",
    "                if j - i >= max_length:\n",
    "                    yield mask\n",
    "            else:\n",
    "                yield mask\n",
    "                \n",
    "def all_consecutive_masks2(tokenized_text, max_length = -1):\n",
    "    # WITHOUT empty and full sets!\n",
    "    s = list(range(len(tokenized_text)))\n",
    "    x = len(s)\n",
    "    for i in range(x+1):\n",
    "        for j in range(i+1, x+1):\n",
    "            mask = s[i:j]\n",
    "            if max_length > 0:\n",
    "                if j - i <= max_length:\n",
    "                    yield mask\n",
    "            else:\n",
    "                yield mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "ex = {\"facts\": \"5.  The applicant was born in 1983 and is detained in Sztum. 6.  At the time of the events in question, the applicant was serving a prison sentence in the Barczewo prison. 7.  On 8 January 2011 the applicant\\u2019s grandmother died. On 10 January 2011 the applicant lodged a request with the Director of Prison and the Penitentiary judge for leave to attend her funeral which was to take place on 12 January 2011. Together with his application he submitted a statement from his sister E.K. who confirmed that she would personally collect the applicant from prison and bring him back after the funeral. 8.  On 11 January 2011 the Penitentiary judge of the Olsztyn Regional Court (S\\u0119dzia Penitencjarny S\\u0105du Okr\\u0119gowego w Olsztynie) allowed the applicant to attend the funeral under prison officers\\u2019 escort. The reasoning of the decision read as follows:\\n\\u201cIn view of [the applicant\\u2019s] multiple convictions and his long term of imprisonment there is no guarantee that he will return to prison\\u201d 9.  The applicant refused to attend the funeral, since he believed his appearance under escort of uniformed officers would create a disturbance during the ceremony. 10.  On the same day the applicant lodged an appeal with the Olsztyn Regional Court (S\\u0105d Okr\\u0119gowy) complaining that the compassionate leave was granted under escort and also that he was only allowed to participate in the funeral (not the preceding church service). 11.  On 3 February 2011 the Olsztyn Regional Court upheld the Penitentiary judge\\u2019s decision and dismissed the appeal. The court stressed that the applicant had been allowed to participate in the funeral under prison officers\\u2019 escort. It further noted that the applicant was a habitual offender sentenced to a long term of imprisonment therefore there was no positive criminological prognosis and no guarantee that he would have returned to prison after the ceremony.\", \"claims\": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], \"outcomes\": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"case_no\": \"20488/11\"}\n",
    "\n",
    "claims = ex[\"claims\"]\n",
    "outcomes = ex[\"outcomes\"]\n",
    "foils = [0 if c == 0 else 1 if c == 1 and o == 1 else 2 for c, o in zip(claims, outcomes)]\n",
    "\n",
    "foil = ex['gold_label']\n",
    "\n",
    "out = predictor.predict_json(ex)\n",
    "encoded_orig = out['encoded_representations']\n",
    "\n",
    "fact = out['label']\n",
    "print('Predicted: ', fact)\n",
    "\n",
    "# assert fact != foil, \"Fact should be different from the foil (if not, pick a different foil)\"\n",
    "\n",
    "ex['sentence1'] = ex['sentence1'].split()\n",
    "ex['sentence2'] = ex['sentence2'].split()\n",
    "\n",
    "tok.convert_tokens_to_string(out['tokens'])\n",
    "\n",
    "masks1 = [[]]  # change this if you also want to mask out parts of the premise.\n",
    "masks2 = list(all_consecutive_masks2(ex['sentence2'], max_length=1))\n",
    "encoded = []\n",
    "mask_mapping = []\n",
    "preds = np.zeros(shape=(len(masks1), len(masks2)))\n",
    "\n",
    "for m1_i, m1 in enumerate(masks1):\n",
    "    masked1 = list(ex['sentence1'])\n",
    "    for i in m1:\n",
    "        masked1[i] = '<mask>'\n",
    "    masked1 = ' '.join(masked1)\n",
    "        \n",
    "    for m2_i, m2 in enumerate(masks2):\n",
    "        masked2 = list(ex['sentence2'])\n",
    "        for i in m2:\n",
    "            masked2[i] = '<mask>'\n",
    "        masked2 = ' '.join(masked2)\n",
    "            \n",
    "        masked_ex = {\n",
    "            \"sentence1\": masked1,\n",
    "            \"sentence2\": masked2\n",
    "        }\n",
    "        \n",
    "        masked_out = predictor.predict_json(masked_ex)\n",
    "#         if masked_out['label'] != foil:\n",
    "#             continue\n",
    "        \n",
    "        print(m1_i, m2_i)\n",
    "        print(f\"{masked1}\\n{masked2}\")\n",
    "        print(masked_out['label'])\n",
    "        encoded.append(masked_out['encoded_representations'])\n",
    "        mask_mapping.append((m1_i, m2_i))\n",
    "        \n",
    "        print(\"====\")\n",
    "        \n",
    "encoded = np.array(encoded)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foil = 'neutral'\n",
    "\n",
    "fact_idx = label2index[fact]\n",
    "foil_idx = label2index[foil]\n",
    "print('fact:', index2label[fact_idx])\n",
    "print('foil:', index2label[foil_idx])\n",
    "num_classifiers = 100\n",
    "\n",
    "classifier_w = np.load(f\"{model_path}/w.npy\")\n",
    "classifier_b = np.load(f\"{model_path}/b.npy\")\n",
    "\n",
    "u = classifier_w[fact_idx] - classifier_w[foil_idx]\n",
    "contrastive_projection = np.outer(u, u) / np.dot(u, u)\n",
    "\n",
    "print(contrastive_projection.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from scipy.stats import entropy\n",
    "from scipy.special import softmax\n",
    "\n",
    "z_all = encoded_orig \n",
    "z_h = encoded \n",
    "z_all_row = encoded_orig @ contrastive_projection\n",
    "z_h_row = encoded @ contrastive_projection\n",
    "\n",
    "prediction_probabilities = softmax(z_all_row @ classifier_w.T + classifier_b)\n",
    "prediction_probabilities = np.tile(prediction_probabilities, (z_h_row.shape[0], 1))\n",
    "\n",
    "prediction_probabilities_del = softmax(z_h_row @ classifier_w.T + classifier_b, axis=1)\n",
    "\n",
    "p = prediction_probabilities[:, [fact_idx, foil_idx]]\n",
    "q = prediction_probabilities_del[:, [fact_idx, foil_idx]]\n",
    "\n",
    "p = p / p.sum(axis=1).reshape(-1, 1)\n",
    "q = q / q.sum(axis=1).reshape(-1, 1)\n",
    "distances = (p[:, 0] - q[:, 0])\n",
    "\n",
    "print(' '.join(ex['sentence1']))\n",
    "print(' '.join(ex['sentence2']))\n",
    "\n",
    "print(\"=========\\n=======Farthest masks:=======\")    \n",
    "    \n",
    "highlight_rankings = np.argsort(-distances)\n",
    "\n",
    "for i in range(4):\n",
    "    rank = highlight_rankings[i]\n",
    "    m1_i, m2_i = mask_mapping[rank]\n",
    "    \n",
    "    masked1 = list(ex['sentence1'])\n",
    "    for k in masks1[m1_i]:\n",
    "        masked1[k] = '<m>'\n",
    "    masked1 = ' '.join(masked1)\n",
    "    \n",
    "    masked2 = list(ex['sentence2'])\n",
    "    for k in masks2[m2_i]:\n",
    "        masked2[k] = '<m>'\n",
    "    masked2 = ' '.join(masked2)\n",
    "    \n",
    "    print(masked1)\n",
    "    print(masked2)\n",
    "    print(np.round(distances[rank], 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
